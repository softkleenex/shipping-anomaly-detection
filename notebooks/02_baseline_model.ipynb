{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline ëª¨ë¸ êµ¬ì¶•\n",
    "\n",
    "## ëª©í‘œ\n",
    "- Macro-F1 Score > 0.9 ë‹¬ì„±\n",
    "- ë‹¤ì–‘í•œ ëª¨ë¸ ì‹¤í—˜ ë° ìµœì  ëª¨ë¸ ì„ ì •\n",
    "\n",
    "## ì „ëµ\n",
    "1. ê°„ë‹¨í•œ ì „ì²˜ë¦¬ + ê¸°ë³¸ ëª¨ë¸ë¡œ ì‹œì‘\n",
    "2. ì ì§„ì ìœ¼ë¡œ ë³µì¡í•œ ëª¨ë¸ ì ìš©\n",
    "3. êµì°¨ ê²€ì¦ìœ¼ë¡œ ì•ˆì •ì„± í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix, make_scorer\n",
    "\n",
    "# Models\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ì¬í˜„ì„±ì„ ìœ„í•œ ì‹œë“œ ì„¤ì •\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "print('ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ ì™„ë£Œ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë°ì´í„° ë¡œë“œ\n",
    "train = pd.read_csv('../data/train.csv')\n",
    "test = pd.read_csv('../data/test.csv')\n",
    "submission = pd.read_csv('../data/sample_submission.csv')\n",
    "\n",
    "# í”¼ì²˜ì™€ íƒ€ê²Ÿ ë¶„ë¦¬\n",
    "feature_cols = [col for col in train.columns if col not in ['ID', 'target']]\n",
    "X_train_full = train[feature_cols]\n",
    "y_train_full = train['target']\n",
    "X_test = test[feature_cols]\n",
    "\n",
    "print(f\"Train shape: {X_train_full.shape}\")\n",
    "print(f\"Test shape: {X_test.shape}\")\n",
    "print(f\"Target classes: {sorted(y_train_full.unique())}\")\n",
    "print(f\"Number of classes: {y_train_full.nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/Validation ë¶„í•  (í™€ë“œì•„ì›ƒ ê²€ì¦ìš©)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_full, y_train_full, \n",
    "    test_size=0.2, \n",
    "    random_state=RANDOM_STATE, \n",
    "    stratify=y_train_full\n",
    ")\n",
    "\n",
    "print(f\"Train set: {X_train.shape}\")\n",
    "print(f\"Validation set: {X_val.shape}\")\n",
    "print(f\"\\nTarget distribution in train:\")\n",
    "print(y_train.value_counts(normalize=True).sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìŠ¤ì¼€ì¼ë§\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_train_full_scaled = scaler.fit_transform(X_train_full)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"ìŠ¤ì¼€ì¼ë§ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Baseline ëª¨ë¸ í•™ìŠµ ë° í‰ê°€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í‰ê°€ í•¨ìˆ˜\n",
    "def evaluate_model(model, X_train, y_train, X_val, y_val, model_name):\n",
    "    \"\"\"ëª¨ë¸ í•™ìŠµ ë° í‰ê°€\"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # í•™ìŠµ\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # ì˜ˆì¸¡\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_val_pred = model.predict(X_val)\n",
    "    \n",
    "    # Macro F1 Score ê³„ì‚°\n",
    "    train_f1 = f1_score(y_train, y_train_pred, average='macro')\n",
    "    val_f1 = f1_score(y_val, y_val_pred, average='macro')\n",
    "    \n",
    "    # ê° í´ë˜ìŠ¤ë³„ F1 Score\n",
    "    class_f1 = f1_score(y_val, y_val_pred, average=None)\n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    print(f\"Train Macro F1: {train_f1:.4f}\")\n",
    "    print(f\"Val Macro F1: {val_f1:.4f}\")\n",
    "    print(f\"Training time: {elapsed_time:.2f} seconds\")\n",
    "    print(f\"\\nClass-wise F1 scores:\")\n",
    "    for i, f1 in enumerate(class_f1):\n",
    "        print(f\"  Class {i}: {f1:.4f}\")\n",
    "    \n",
    "    return model, val_f1, class_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ëª¨ë¸ ì •ì˜\n",
    "models = {\n",
    "    'RandomForest': RandomForestClassifier(\n",
    "        n_estimators=200,\n",
    "        max_depth=15,\n",
    "        min_samples_split=5,\n",
    "        min_samples_leaf=2,\n",
    "        random_state=RANDOM_STATE,\n",
    "        n_jobs=-1,\n",
    "        class_weight='balanced'\n",
    "    ),\n",
    "    'ExtraTrees': ExtraTreesClassifier(\n",
    "        n_estimators=200,\n",
    "        max_depth=15,\n",
    "        min_samples_split=5,\n",
    "        min_samples_leaf=2,\n",
    "        random_state=RANDOM_STATE,\n",
    "        n_jobs=-1,\n",
    "        class_weight='balanced'\n",
    "    ),\n",
    "    'XGBoost': XGBClassifier(\n",
    "        n_estimators=300,\n",
    "        max_depth=8,\n",
    "        learning_rate=0.1,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=RANDOM_STATE,\n",
    "        n_jobs=-1,\n",
    "        objective='multi:softprob',\n",
    "        eval_metric='mlogloss'\n",
    "    ),\n",
    "    'LightGBM': LGBMClassifier(\n",
    "        n_estimators=300,\n",
    "        max_depth=8,\n",
    "        learning_rate=0.1,\n",
    "        num_leaves=31,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=RANDOM_STATE,\n",
    "        n_jobs=-1,\n",
    "        objective='multiclass',\n",
    "        metric='multi_logloss',\n",
    "        class_weight='balanced',\n",
    "        verbose=-1\n",
    "    ),\n",
    "    'CatBoost': CatBoostClassifier(\n",
    "        iterations=500,\n",
    "        depth=8,\n",
    "        learning_rate=0.1,\n",
    "        random_state=RANDOM_STATE,\n",
    "        verbose=False,\n",
    "        auto_class_weights='Balanced'\n",
    "    )\n",
    "}\n",
    "\n",
    "# ê²°ê³¼ ì €ì¥\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ëª¨ë“  ëª¨ë¸ í•™ìŠµ ë° í‰ê°€\n",
    "for name, model in models.items():\n",
    "    trained_model, val_f1, class_f1 = evaluate_model(\n",
    "        model, X_train_scaled, y_train, X_val_scaled, y_val, name\n",
    "    )\n",
    "    results[name] = {\n",
    "        'model': trained_model,\n",
    "        'val_f1': val_f1,\n",
    "        'class_f1': class_f1\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê²°ê³¼ ìš”ì•½\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ëª¨ë¸ ì„±ëŠ¥ ìš”ì•½ (Validation Set)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "summary_df = pd.DataFrame([\n",
    "    {'Model': name, 'Macro F1': res['val_f1']} \n",
    "    for name, res in results.items()\n",
    "]).sort_values('Macro F1', ascending=False)\n",
    "\n",
    "display(summary_df)\n",
    "\n",
    "best_model_name = summary_df.iloc[0]['Model']\n",
    "best_f1 = summary_df.iloc[0]['Macro F1']\n",
    "\n",
    "print(f\"\\nğŸ† Best Model: {best_model_name}\")\n",
    "print(f\"   Macro F1 Score: {best_f1:.4f}\")\n",
    "\n",
    "if best_f1 >= 0.9:\n",
    "    print(\"\\nâœ… ëª©í‘œ ë‹¬ì„±! (Macro F1 >= 0.9)\")\n",
    "else:\n",
    "    print(f\"\\nâš ï¸ ëª©í‘œ ë¯¸ë‹¬ (í˜„ì¬: {best_f1:.4f}, ëª©í‘œ: 0.9)\")\n",
    "    print(\"   ì¶”ê°€ ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. K-Fold êµì°¨ ê²€ì¦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë² ìŠ¤íŠ¸ ëª¨ë¸ë¡œ K-Fold êµì°¨ ê²€ì¦\n",
    "best_model = results[best_model_name]['model']\n",
    "\n",
    "# Stratified K-Fold\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "# Macro F1 scorer\n",
    "macro_f1_scorer = make_scorer(f1_score, average='macro')\n",
    "\n",
    "# êµì°¨ ê²€ì¦\n",
    "print(f\"\\n{best_model_name} ëª¨ë¸ 5-Fold êµì°¨ ê²€ì¦ ì¤‘...\")\n",
    "cv_scores = cross_val_score(\n",
    "    best_model.__class__(**best_model.get_params()),\n",
    "    X_train_full_scaled,\n",
    "    y_train_full,\n",
    "    cv=skf,\n",
    "    scoring=macro_f1_scorer,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(f\"\\n5-Fold CV Results:\")\n",
    "print(f\"Scores: {cv_scores}\")\n",
    "print(f\"Mean: {cv_scores.mean():.4f}\")\n",
    "print(f\"Std: {cv_scores.std():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature Importance ë¶„ì„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance (Tree ê¸°ë°˜ ëª¨ë¸ë§Œ)\n",
    "if hasattr(best_model, 'feature_importances_'):\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': feature_cols,\n",
    "        'importance': best_model.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    print(f\"\\nTop 15 Important Features ({best_model_name}):\")\n",
    "    display(feature_importance.head(15))\n",
    "    \n",
    "    # ì‹œê°í™”\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    top_features = feature_importance.head(20)\n",
    "    plt.barh(range(len(top_features)), top_features['importance'].values)\n",
    "    plt.yticks(range(len(top_features)), top_features['feature'].values)\n",
    "    plt.xlabel('Importance')\n",
    "    plt.title(f'Top 20 Feature Importances - {best_model_name}')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. ìµœì¢… ëª¨ë¸ í•™ìŠµ ë° ì˜ˆì¸¡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì „ì²´ ë°ì´í„°ë¡œ ìµœì¢… ëª¨ë¸ í•™ìŠµ\n",
    "print(f\"\\nìµœì¢… ëª¨ë¸ í•™ìŠµ ì¤‘ ({best_model_name})...\")\n",
    "\n",
    "final_model = best_model.__class__(**best_model.get_params())\n",
    "final_model.fit(X_train_full_scaled, y_train_full)\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ë°ì´í„° ì˜ˆì¸¡\n",
    "test_predictions = final_model.predict(X_test_scaled)\n",
    "\n",
    "print(\"ì˜ˆì¸¡ ì™„ë£Œ!\")\n",
    "print(f\"\\nì˜ˆì¸¡ ë¶„í¬:\")\n",
    "print(pd.Series(test_predictions).value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì œì¶œ íŒŒì¼ ìƒì„±\n",
    "submission['target'] = test_predictions\n",
    "\n",
    "# ì €ì¥\n",
    "submission_filename = f'../submissions/baseline_{best_model_name.lower()}_f1_{best_f1:.4f}.csv'\n",
    "submission.to_csv(submission_filename, index=False)\n",
    "\n",
    "print(f\"\\nâœ… ì œì¶œ íŒŒì¼ ìƒì„± ì™„ë£Œ: {submission_filename}\")\n",
    "print(\"\\nì œì¶œ íŒŒì¼ ë¯¸ë¦¬ë³´ê¸°:\")\n",
    "display(submission.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. ê°œì„  ë°©í–¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"ğŸ“ˆ ì„±ëŠ¥ ê°œì„  ë°©í–¥\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if best_f1 < 0.9:\n",
    "    print(\"\"\"\n",
    "í˜„ì¬ ì„±ëŠ¥ì´ ëª©í‘œì— ë¯¸ë‹¬í•˜ë¯€ë¡œ ë‹¤ìŒ ë°©ë²•ë“¤ì„ ì‹œë„í•´ì•¼ í•©ë‹ˆë‹¤:\n",
    "\n",
    "1. Feature Engineering ê°•í™”\n",
    "   - í”¼ì²˜ ê°„ ìƒí˜¸ì‘ìš© (ê³±ì…ˆ, ë‚˜ëˆ—ì…ˆ)\n",
    "   - í†µê³„ì  íŠ¹ì§• (ê·¸ë£¹ë³„ í‰ê· , í‘œì¤€í¸ì°¨)\n",
    "   - ë‹¤í•­ì‹ íŠ¹ì§•\n",
    "   - PCA, t-SNE ë“± ì°¨ì› ì¶•ì†Œ\n",
    "\n",
    "2. í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”\n",
    "   - Optunaë¥¼ ì´ìš©í•œ ë² ì´ì§€ì•ˆ ìµœì í™”\n",
    "   - GridSearchCV ë˜ëŠ” RandomizedSearchCV\n",
    "\n",
    "3. ì•™ìƒë¸” ë°©ë²•\n",
    "   - Voting Classifier\n",
    "   - Stacking\n",
    "   - Blending\n",
    "\n",
    "4. í´ë˜ìŠ¤ ë¶ˆê· í˜• ì²˜ë¦¬\n",
    "   - SMOTE ë“± ì˜¤ë²„ìƒ˜í”Œë§\n",
    "   - í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ì¡°ì •\n",
    "\n",
    "5. ì‹ ê²½ë§ ëª¨ë¸\n",
    "   - TabNet\n",
    "   - Deep Neural Network\n",
    "    \"\"\")\n",
    "else:\n",
    "    print(\"\"\"\n",
    "âœ… ëª©í‘œ ì„±ëŠ¥ì„ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤!\n",
    "\n",
    "ì¶”ê°€ ê°œì„ ì„ ìœ„í•œ ì œì•ˆ:\n",
    "1. ì•™ìƒë¸”ë¡œ ì•ˆì •ì„± í–¥ìƒ\n",
    "2. í›„ì²˜ë¦¬(Post-processing) ì ìš©\n",
    "3. Pseudo-labeling ê³ ë ¤\n",
    "    \"\"\")\n",
    "\n",
    "print(f\"\\ní˜„ì¬ ìµœê³  ì„±ëŠ¥: {best_f1:.4f} ({best_model_name})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}